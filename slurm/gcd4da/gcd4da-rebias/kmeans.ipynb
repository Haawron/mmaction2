{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from pathlib import Path\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import imageio\n",
    "\n",
    "import shutil\n",
    "import os\n",
    "if not os.getcwd().endswith('haawron_mmaction2'):\n",
    "    os.chdir('../..')\n",
    "assert os.getcwd().endswith('haawron_mmaction2')\n",
    "\n",
    "np.random.seed(999)  # numpy & sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmaction.core import (mean_average_precision, mean_class_accuracy,\n",
    "                    mmit_mean_average_precision, top_k_accuracy,\n",
    "                    confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_source (4666,)\n",
      "train_target (5275,)\n",
      "valid (1507,)\n",
      "test (753,)\n"
     ]
    }
   ],
   "source": [
    "anns = {}\n",
    "for split_name, p_ann in zip(\n",
    "    ['train_source', 'train_target', 'valid', 'test'],\n",
    "    [\n",
    "        Path(r'data/epic-kitchens-100/filelist_P02_train_open.txt'),  # to extract only closed\n",
    "        Path(r'data/epic-kitchens-100/filelist_P04_train_open.txt'),\n",
    "        Path(r'data/epic-kitchens-100/filelist_P04_valid_open.txt'),\n",
    "        Path(r'data/epic-kitchens-100/filelist_P04_test_open.txt')\n",
    "    ]\n",
    "):\n",
    "    with p_ann.open('r') as f:\n",
    "        reader = csv.reader(f, delimiter=' ')\n",
    "        ann = [int(label) for _, _, _, label in reader]\n",
    "        ann = np.array(ann)\n",
    "        anns[split_name] = ann\n",
    "        print(split_name, ann.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_source (2816, 512)\n",
      "train_target (5275, 512)\n",
      "valid (1507, 512)\n",
      "test (753, 512)\n"
     ]
    }
   ],
   "source": [
    "Xs = {}\n",
    "# p_root = Path(r'work_dirs/sanity/ek100/tsm/GCD4DA/P02_P04/19135__GCD4DA_tsm_ek100_sanity_one_way/0/20220506-045539')\n",
    "p_root = Path(r'work_dirs/sanity/ek100/tsm/GCD4DA/P02_P04/19390__GCD4DA_tsm_ek100_sanity_one_way_phase1/0/20220509-222653')\n",
    "for split_name, p_feature in zip(\n",
    "    ['train_source', 'train_target', 'valid', 'test'],\n",
    "    [\n",
    "        p_root / 'features/P02_train_open.pkl',\n",
    "        p_root / 'features/P04_train_open.pkl',\n",
    "        p_root / 'features/P04_valid_open.pkl',\n",
    "        p_root / 'features/P04_test_open.pkl',\n",
    "    ]\n",
    "):\n",
    "    with p_feature.open('rb') as f:\n",
    "        X = pickle.load(f)\n",
    "        X = np.array(X)\n",
    "        if split_name == 'train_source':\n",
    "            X = X[anns[split_name]!=5]  # only closed\n",
    "        Xs[split_name] = X\n",
    "    print(split_name, X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def cosine(X, y, norm_X=None):\n",
    "    norm_X = norm_X if norm_X is not None else np.einsum('ij,ji->i', X, X.T)  # (X @ X.T).diagnoal()\n",
    "    sim = X @ y / (norm_X * (y@y))**.5\n",
    "    sim[(sim>1.)  & (abs(sim-1.)<1e-4)] = 1.\n",
    "    sim[(sim<-1.) & (abs(sim+1.)<1e-4)] = -1.\n",
    "    return sim\n",
    "\n",
    "def get_kmeans_model(k):\n",
    "    # 1. get initial centroids\n",
    "    # 1-1. semi. k-means: centroids are mean vector for each class for labeled data\n",
    "    centroids = [] \n",
    "    centroid_args = []\n",
    "    for c in range(5):\n",
    "        ann_train_source_closed = anns['train_source'][anns['train_source'] != 5]\n",
    "        centroids.append(Xs['train_source'][ann_train_source_closed==c].mean(axis=0))\n",
    "    # 1-2. k-means++: centroids are initialized by random choices w.p. their distances to the last picked centroid\n",
    "    new_centroid = centroids[-1]\n",
    "    X = np.concatenate((Xs['train_source'], Xs['train_target']), axis=0)\n",
    "    norm_X = np.einsum('ij,ji->i', X, X.T)  # (X @ X.T).diagnoal()\n",
    "    for _ in range(k-5):\n",
    "        y = new_centroid\n",
    "        sim = cosine(X, y, norm_X)\n",
    "        assertion = ((-1 <= sim) & (sim <= 1))\n",
    "        assert assertion.all(), sim[~assertion]\n",
    "        d = np.arccos(sim)\n",
    "        d **= .3  # Heuristics: d = sqrt(theta)\n",
    "        d[centroid_args] = 0\n",
    "        centroid_arg = np.random.choice(X.shape[0], p=d/d.sum())\n",
    "        centroid_args.append(centroid_arg)\n",
    "        new_centroid = X[centroid_arg]\n",
    "        centroids.append(new_centroid) \n",
    "    centroids = np.array(centroids)\n",
    "    # 2. train\n",
    "    model = KMeans(n_clusters=k, init=centroids, n_init=1, tol=1e-7).fit(X)\n",
    "    return model\n",
    "\n",
    "def get_model_score(model, verbose=True, os=True):\n",
    "    scores = {}\n",
    "    for split_name in ['train_target', 'valid', 'test']:\n",
    "        if verbose:\n",
    "            print(split_name.split('_')[0])\n",
    "\n",
    "        pred_test = model.predict(Xs[split_name])\n",
    "        pred_test = np.minimum(5, pred_test, dtype=np.int64)\n",
    "        conf = confusion_matrix(pred_test, anns[split_name])\n",
    "        \n",
    "        recalls = conf.diagonal() / conf.sum(axis=1)\n",
    "        score = 100 * (recalls.mean() if os else recalls[:5].mean())\n",
    "        scores[split_name] = score\n",
    "        if verbose:\n",
    "            print(conf)\n",
    "            print(f'{score:.1f}')\n",
    "            print()\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/hyogun/anaconda3/envs/open-mmlab/lib/python3.7/site-packages/threadpoolctl.py:762: RuntimeWarning: \n",
      "Found Intel OpenMP ('libiomp') and LLVM OpenMP ('libomp') loaded at\n",
      "the same time. Both libraries are known to be incompatible and this\n",
      "can cause random crashes or deadlocks on Linux when loaded in the\n",
      "same Python program.\n",
      "Using threadpoolctl may cause crashes or deadlocks. For more\n",
      "information and possible workarounds, please see\n",
      "    https://github.com/joblib/threadpoolctl/blob/master/multiple_openmp.md\n",
      "\n",
      "  warnings.warn(msg, RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best test score 39.0 at k=8\n"
     ]
    }
   ],
   "source": [
    "n_tries = 20\n",
    "rows_os, rows_os_star = [], []\n",
    "ks = list(range(5, 16)) + [30, 50, 100]\n",
    "global_best_model = None\n",
    "global_best_test_score = 0\n",
    "global_best_k = 0\n",
    "for k in ks:\n",
    "    local_best_model = None\n",
    "    local_best_scores = None\n",
    "    local_best_test_score = 0\n",
    "    for _ in range(n_tries):\n",
    "        model = get_kmeans_model(k)\n",
    "        scores_os = get_model_score(model, False)\n",
    "        scores_os_star = get_model_score(model, False, False)\n",
    "        current_test_score = scores_os['test']\n",
    "        if local_best_test_score < current_test_score:\n",
    "            local_best_model = model\n",
    "            local_best_scores = scores_os, scores_os_star\n",
    "            local_best_test_score = current_test_score\n",
    "    rows_os.append(pd.Series(local_best_scores)[0])\n",
    "    rows_os_star.append(pd.Series(local_best_scores)[1])\n",
    "    if global_best_test_score < local_best_test_score:\n",
    "        global_best_model = local_best_model\n",
    "        global_best_test_score = local_best_test_score\n",
    "        global_best_k = k\n",
    "print(f'best test score {global_best_test_score:.1f} at k={global_best_k}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.04222293, 0.04312205, 0.04722004, 0.04772336, 0.05112299,\n",
       "       0.05018607, 0.05731261, 0.04872426], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C = global_best_model.cluster_centers_\n",
    "(C ** 2).mean(axis=1) ** .5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>30</th>\n",
       "      <th>50</th>\n",
       "      <th>100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train_target</th>\n",
       "      <td>12.3</td>\n",
       "      <td>18.4</td>\n",
       "      <td>20.4</td>\n",
       "      <td>14.5</td>\n",
       "      <td>14.6</td>\n",
       "      <td>14.4</td>\n",
       "      <td>16.1</td>\n",
       "      <td>13.9</td>\n",
       "      <td>19.5</td>\n",
       "      <td>25.2</td>\n",
       "      <td>12.3</td>\n",
       "      <td>16.5</td>\n",
       "      <td>16.3</td>\n",
       "      <td>17.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>valid</th>\n",
       "      <td>12.7</td>\n",
       "      <td>16.0</td>\n",
       "      <td>14.4</td>\n",
       "      <td>13.7</td>\n",
       "      <td>13.7</td>\n",
       "      <td>20.5</td>\n",
       "      <td>16.9</td>\n",
       "      <td>14.1</td>\n",
       "      <td>12.7</td>\n",
       "      <td>14.6</td>\n",
       "      <td>13.6</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.4</td>\n",
       "      <td>16.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>28.2</td>\n",
       "      <td>29.6</td>\n",
       "      <td>28.0</td>\n",
       "      <td>27.9</td>\n",
       "      <td>22.9</td>\n",
       "      <td>26.0</td>\n",
       "      <td>27.8</td>\n",
       "      <td>22.4</td>\n",
       "      <td>21.5</td>\n",
       "      <td>25.7</td>\n",
       "      <td>26.1</td>\n",
       "      <td>19.4</td>\n",
       "      <td>20.5</td>\n",
       "      <td>17.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               5     6     7     8     9     10    11    12    13    14   \\\n",
       "train_target  12.3  18.4  20.4  14.5  14.6  14.4  16.1  13.9  19.5  25.2   \n",
       "valid         12.7  16.0  14.4  13.7  13.7  20.5  16.9  14.1  12.7  14.6   \n",
       "test          28.2  29.6  28.0  27.9  22.9  26.0  27.8  22.4  21.5  25.7   \n",
       "\n",
       "               15    30    50    100  \n",
       "train_target  12.3  16.5  16.3  17.6  \n",
       "valid         13.6  15.0  20.4  16.5  \n",
       "test          26.1  19.4  20.5  17.7  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('precision', 1)\n",
    "df = pd.DataFrame.from_records(rows_os, columns=['train_target', 'valid', 'test'], index=ks)\n",
    "df.name = 'OS'\n",
    "df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>30</th>\n",
       "      <th>50</th>\n",
       "      <th>100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train_target</th>\n",
       "      <td>25.1</td>\n",
       "      <td>28.1</td>\n",
       "      <td>10.4</td>\n",
       "      <td>12.8</td>\n",
       "      <td>10.3</td>\n",
       "      <td>6.2</td>\n",
       "      <td>5.3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>16.6</td>\n",
       "      <td>6.8</td>\n",
       "      <td>6.7</td>\n",
       "      <td>9.7</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>valid</th>\n",
       "      <td>17.4</td>\n",
       "      <td>10.8</td>\n",
       "      <td>26.9</td>\n",
       "      <td>6.9</td>\n",
       "      <td>11.1</td>\n",
       "      <td>8.7</td>\n",
       "      <td>9.2</td>\n",
       "      <td>8.8</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>16.9</td>\n",
       "      <td>8.9</td>\n",
       "      <td>12.9</td>\n",
       "      <td>15.7</td>\n",
       "      <td>9.5</td>\n",
       "      <td>18.1</td>\n",
       "      <td>14.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>13.6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.8</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               5     6     7     8     9     10    11   12    13   14   15   \\\n",
       "train_target  25.1  28.1  10.4  12.8  10.3   6.2   5.3  6.0  16.6  6.8  6.7   \n",
       "valid         17.4  10.8  26.9   6.9  11.1   8.7   9.2  8.8   5.0  5.1  3.0   \n",
       "test          16.9   8.9  12.9  15.7   9.5  18.1  14.0  3.4  13.6  4.0  9.8   \n",
       "\n",
       "              30   50   100  \n",
       "train_target  9.7  2.7  0.9  \n",
       "valid         4.0  1.4  0.8  \n",
       "test          3.1  0.5  0.6  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame.from_records(rows_os_star, columns=['train_target', 'valid', 'test'], index=ks)\n",
    "df.name = 'OS*'\n",
    "df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_os_star = global_best_model.transform(Xs['test'])[:,:5]\n",
    "pred_os_star = score_os_star.argmin(axis=1)\n",
    "conf = confusion_matrix(pred_os_star, anns['test'])[:5, :5]\n",
    "recalls = conf.diagonal() / conf.sum(axis=1)\n",
    "print(recalls)\n",
    "print(recalls.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = global_best_model.predict(Xs['test'])\n",
    "conf = confusion_matrix(np.minimum(pred, 5, dtype=np.int64), anns['test'])\n",
    "recalls = conf.diagonal() / conf.sum(axis=1)\n",
    "print(conf)\n",
    "with np.printoptions(precision=2):\n",
    "    print(recalls)\n",
    "    print(f'OS:  {100*recalls.mean():.1f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_to_label = ['take', 'put', 'wash', 'open', 'close', 'unknown']\n",
    "num_samples = 5\n",
    "correct = np.minimum(pred, 5)==anns['test']\n",
    "args_correct, args_incorrect = {}, {}\n",
    "for c in range(global_best_model.n_clusters):\n",
    "    args = ((pred==c) & correct).nonzero()[0]\n",
    "    args_correct[c]   = args if args.shape[0] < num_samples else np.random.choice(args, num_samples, replace=False)\n",
    "    args = ((pred==c) & ~correct).nonzero()[0]\n",
    "    args_incorrect[c] = args if args.shape[0] < num_samples else np.random.choice(args, num_samples, replace=False)\n",
    "args_correct, args_incorrect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "Counter(pred), Counter(anns['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_ann = Path(r'data/epic-kitchens-100/filelist_P04_test_open.txt')  # to extract only closed\n",
    "with p_ann.open('r') as f:\n",
    "    reader = csv.reader(f, delimiter=' ')\n",
    "    clips = [(Path(rel_p), int(start), int(length), int(label)) for rel_p, start, length, label in reader]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_base_video_dir = Path(r'data/epic-kitchens-100/EPIC-KITCHENS')\n",
    "p_out_dir_base = Path('work_dirs/hello/clusters/P02_P04')\n",
    "max_gif_length = 200\n",
    "\n",
    "if p_out_dir_base.is_dir():\n",
    "    shutil.rmtree(p_out_dir_base)\n",
    "\n",
    "for correctness, args in zip(['o', 'x'], [args_correct, args_incorrect]):\n",
    "    p_out_dir = p_out_dir_base / correctness\n",
    "    if not p_out_dir.is_dir():\n",
    "        p_out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    for c in range(global_best_model.n_clusters):\n",
    "        print(c, end='\\t')\n",
    "        for i, (rel_p, start, length, label) in enumerate(np.array(clips)[args[c]]):\n",
    "            p_video = p_base_video_dir / rel_p\n",
    "            with imageio.get_writer(p_out_dir / f'k{c:02d}_{i:02d}_{idx_to_label[min(5, c)]}_{idx_to_label[min(5, label)]}.gif', mode='I', duration=1/30) as writer:\n",
    "                for frame_idx in range(start, start+min(max_gif_length,length)+1):\n",
    "                    p_frame = p_video / f'frame_{frame_idx:010d}.jpg'\n",
    "                    image = imageio.imread(p_frame)\n",
    "                    writer.append_data(image)\n",
    "            print(i, end=' ')\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "p_centroid = p_root / 'centroids.pkl'\n",
    "with p_centroid.open('wb') as f:\n",
    "    pickle.dump(global_best_model.cluster_centers_, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ".shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_ann_train_target = Path(r'data/epic-kitchens-100/filelist_P04_train_open.txt')  # to extract only closed\n",
    "with p_ann_train_target.open('r') as f:\n",
    "    reader = csv.reader(f, delimiter=' ')\n",
    "    clips = list(reader)\n",
    "\n",
    "pseudo_labels = global_best_model.predict(Xs['train_target'])\n",
    "p_pseudo = p_root / f'filelist_pseudo_P04_k{global_best_k:03d}_one_way.txt'\n",
    "with p_pseudo.open('w') as f:\n",
    "    writer = csv.writer(f, delimiter=' ')\n",
    "    for (rel_p, start, length, label), pseudo_label in zip(clips, pseudo_labels):\n",
    "        writer.writerow([rel_p, start, length, pseudo_label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_pseudo"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5bffa9bf2f09109ed8eb2df7a7ed69cac97689136798a3d627c1002bd814088d"
  },
  "kernelspec": {
   "display_name": "Open-MMLab",
   "language": "python",
   "name": "open-mmlab"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
