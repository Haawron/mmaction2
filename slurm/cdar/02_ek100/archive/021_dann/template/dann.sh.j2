#!/bin/bash

#SBATCH -J {{ idx }}_{{ source }}_{{ target }}-dann
#SBATCH -p batch_grad
#SBATCH --gres=gpu:4
#SBATCH --cpus-per-gpu=16
#SBATCH --mem-per-gpu=25G
#SBATCH -t 1-0
#SBATCH -x ariel-g[1,3-5]
#SBATCH --array 0-3%4
#SBATCH -o slurm/logs/slurm-%A_%a-%x.out

current_time=$(date +'%Y%m%d-%H%M%S')


# overleaf table 기준
project='cdar'
task='02_ek100'  # table name
subtask={{ idx }}_{{ source }}_{{ target }}  # column
model='021_dann'  # row
add_on='default'
extra_setting='warmup'  # 'default' if none
path_experiment="${project}/${task}/${subtask}/${model}/${add_on}/${extra_setting}"

workdir="work_dirs/train_output"
workdir="${workdir}/${path_experiment}"
workdir="${workdir}/${SLURM_ARRAY_JOB_ID}__${SLURM_JOB_NAME}/${SLURM_ARRAY_TASK_ID}/${current_time}"

# model selection 할 때 평가를 target domain에서 했음
# 그래서 epoch 10인 애들이 많이 뽑혔고 다른 model의 warmup weight로 쓰기엔 부적함해서 latest로 설정함
declare -A ckpts
ckpts=(
    ['P04_P02']='work_dirs/train_output/cdar/02_ek100/00_P04_P02/02_timesformer/k400/default/542__P04_P02-tsf-warmup/3/20230222-031302/latest.pth'
    ['P22_P02']='work_dirs/train_output/cdar/02_ek100/01_P22_P02/02_timesformer/k400/default/543__P22_P02-tsf-warmup/3/20230222-043835/latest.pth'
    ['P02_P04']='work_dirs/train_output/cdar/02_ek100/02_P02_P04/02_timesformer/k400/default/544__P02_P04-tsf-warmup/3/20230222-072853/latest.pth'
    ['P04_P04']='work_dirs/train_output/cdar/02_ek100/03_P22_P04/02_timesformer/k400/default/545__P22_P04-tsf-warmup/2/20230222-090523/latest.pth'
    ['P02_P22']='work_dirs/train_output/cdar/02_ek100/04_P02_P22/02_timesformer/k400/default/546__P02_P22-tsf-warmup/2/20230222-115636/latest.pth'
    ['P04_P22']='work_dirs/train_output/cdar/02_ek100/05_P04_P22/02_timesformer/k400/default/547__P04_P22-tsf-warmup/2/20230222-133455/latest.pth'
)
ckpt="${ckpts[${subtask#*_}]}"

lrs=(5e-3 1e-3 5e-4 1e-4)
lr="${lrs[SLURM_ARRAY_TASK_ID]}"

config_j2='configs/recognition/cdar/02_ek100/021_dann/template/dann.py.j2'
rendered_dir="${config_j2%template*}rendered"  # **/template/* -> **/rendered
mkdir -p $rendered_dir
config="${rendered_dir}/{{ source }}_{{ target }}_$(basename $config_j2 .j2)"
python slurm/utils/commons/render_template.py -f $config_j2 --source {{ source }} --target {{ target }} > $config

N=$SLURM_GPUS_ON_NODE
OMP_NUM_THREADS=${N} MKL_NUM_THREADS=${N} torchrun --nproc_per_node="${N}" --master_port=$((10000+RANDOM%20000)) tools/train.py $config \
    --launcher pytorch \
    --work-dir "$workdir" \
    --cfg-options optimizer.lr="$lr" load_from=$ckpt \
    --validate --test-last --test-best

exit 0
